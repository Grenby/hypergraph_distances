{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.176600Z",
     "start_time": "2024-10-24T08:06:15.823376Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import os\n",
    "import igraph as ig\n",
    "import pathlib\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specification of data and supplementary dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.180154Z",
     "start_time": "2024-10-24T08:06:16.177530Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_type = '2009-2010'\n",
    "data_type = '2000-2001'\n",
    "# data_type = '1999-2000'\n",
    "# data_type = 'subsample'\n",
    "DATA_PATH = f'../data arxiv/hyperedges_list_arxiv_{data_type}.txt'\n",
    "LINEGRAPH_EDGES_PATH = f'../suplementary/linegraphs/linegraph_weighted_edges_list_{data_type}.txt'\n",
    "LINEGRAPH_NODES_PATH = f'../suplementary/linegraphs/linegraph_weighted_nodes_list_{data_type}.txt'\n",
    "DIST_DIR = \"../suplementary/dist\"\n",
    "CLIQUE_PATH = f\"../suplementary/clique-projections/{data_type}-proj-graph.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.189714Z",
     "start_time": "2024-10-24T08:06:16.181280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8914\n",
      "'hep-ex', 'physics.comp-ph'\n",
      "'math.ag', 'math.cv'\n"
     ]
    }
   ],
   "source": [
    "data_path = DATA_PATH\n",
    "with open(data_path) as file:\n",
    "    line = file.readline()\n",
    "\n",
    "if data_type in [\"subsample\", \"test\"]:\n",
    "    hyperedges_list = line.split('], ')\n",
    "    hyperedges_list = [x.replace('[', '') for x in hyperedges_list]\n",
    "    hyperedges_list = [x.replace(']', '') for x in hyperedges_list]  # removes the last \"]\"\"\n",
    "else:\n",
    "    hyperedges_list = line.split(']\", ')\n",
    "    hyperedges_list = [x.replace('\"[', '') for x in hyperedges_list]\n",
    "    hyperedges_list = [x.replace(']\"', '') for x in hyperedges_list]  # removes the last \"]\"\"\n",
    "\n",
    "print(len(hyperedges_list))\n",
    "print(hyperedges_list[0])\n",
    "print(hyperedges_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.207839Z",
     "start_time": "2024-10-24T08:06:16.191227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205\n",
      "2205\n",
      "[['astro-ph', 'astro-ph.ga'], ['astro-ph', 'cond-mat'], ['astro-ph', 'cond-mat', 'gr-qc', 'hep-ph']]\n",
      "[1 1 2]\n"
     ]
    }
   ],
   "source": [
    "hyperedges_list, counts_list = np.unique(hyperedges_list,\n",
    "                                         return_counts=True)  # counts_list contains info about frequencies of each hyperedge\n",
    "print(len(hyperedges_list))\n",
    "print(len(counts_list))\n",
    "\n",
    "hyperedges_list = [x.replace(\"'\", '') for x in hyperedges_list]\n",
    "hyperedges_list = [x.split(', ') for x in hyperedges_list]\n",
    "print(hyperedges_list[:3])\n",
    "print(counts_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.211960Z",
     "start_time": "2024-10-24T08:06:16.208640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2205\n"
     ]
    }
   ],
   "source": [
    "# left hyperedges of size 1\n",
    "hyperedges_list_ids = [i for i in range(len(hyperedges_list)) if len(hyperedges_list[i]) > 1]\n",
    "print(len(hyperedges_list_ids))\n",
    "if len(hyperedges_list_ids) < len(hyperedges_list):\n",
    "    hyperedges_list = [hyperedges_list[i] for i in hyperedges_list_ids]\n",
    "    counts_list = [counts_list[i] for i in hyperedges_list_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.217096Z",
     "start_time": "2024-10-24T08:06:16.214188Z"
    }
   },
   "outputs": [],
   "source": [
    "# create supplementary dictionary containing nodes as keys and hyperedges to which they are incident as values. It helps to access needed hyperedges faster\n",
    "def get_nodes_to_edges(edges_to_nodes_dict):\n",
    "    nodes_to_edges_dict = {}\n",
    "    for edge, nodes in edges_to_nodes_dict.items():\n",
    "        for node in nodes:\n",
    "            if node in nodes_to_edges_dict.keys():\n",
    "                nodes_to_edges_dict[node].append(edge)\n",
    "            else:\n",
    "                nodes_to_edges_dict[node] = [edge]\n",
    "    return nodes_to_edges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.220792Z",
     "start_time": "2024-10-24T08:06:16.217636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes count = 135\n"
     ]
    }
   ],
   "source": [
    "edges_to_nodes_dict = {i: hyperedges_list[i] for i in\n",
    "                       range(len(hyperedges_list))}  # key = hyperedge, value = nodes in hyperedge\n",
    "edges_to_counts_dict = {i: counts_list[i] for i in range(len(counts_list))}\n",
    "nodes_to_edges_dict = get_nodes_to_edges(\n",
    "    edges_to_nodes_dict)  # key = node, value = list of hyperedges in which the node participates\n",
    "print(f'nodes count = {len(nodes_to_edges_dict.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line-graph construction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.227471Z",
     "start_time": "2024-10-24T08:06:16.221478Z"
    }
   },
   "outputs": [],
   "source": [
    "# weight_function is needed for creation of weighted line graph, w1 (w2) is e1's (e2's) weight in weighted hypergraph\n",
    "def weight_function(e1, e2, w1, w2):\n",
    "    if e1 == e2:\n",
    "        return (1 / w1) * ((1 / 3) * (len(e1) + 1) - 1)\n",
    "    union_len = len(set(e1).union(e2))\n",
    "    intersect_len = len(set(e1).intersection(e2))\n",
    "    return (1 / 2) * (1 / w1 + 1 / w2) * ((1 / 3) * union_len * (1 + 1 / intersect_len) - 1)\n",
    "\n",
    "\n",
    "def generate_weighted_line_graph(edges_to_nodes_dict, edges_to_counts_dict):\n",
    "    file_path = pathlib.Path(LINEGRAPH_EDGES_PATH)\n",
    "\n",
    "    if not file_path.exists():\n",
    "\n",
    "        items = list(edges_to_nodes_dict.items())\n",
    "        line_nodes_ids_dict = {items[i][0]: i for i in\n",
    "                               range(len(items))}  # in line-graph nodes = hyperedges in intial hypergraph\n",
    "        line_edges_list = []\n",
    "        line_edges_weights_list = []\n",
    "\n",
    "        for i in range(len(items)):\n",
    "            edge, nodes = items[i]\n",
    "            line_edges_list.append([i, i])  # our line-graph has self-loops\n",
    "            line_edges_weights_list.append(weight_function(nodes, nodes,\n",
    "                                                           edges_to_counts_dict[edge],\n",
    "                                                           edges_to_counts_dict[edge]))  # add weights of self-loops\n",
    "\n",
    "        for i in tqdm(range(len(items))):\n",
    "            edge, nodes = items[i]\n",
    "            set_nodes = set(nodes)\n",
    "            neighbors = [k for k, v in items if\n",
    "                         not k == edge and\n",
    "                         (len(v) >= len(nodes)) and\n",
    "                         not set_nodes.isdisjoint(v)]  # find hyperedges that intersect with the current one\n",
    "\n",
    "            if len(neighbors) > 0:\n",
    "                for neighbor in neighbors:\n",
    "                    line_edges_list.append([line_nodes_ids_dict[edge], line_nodes_ids_dict[\n",
    "                        neighbor]])  # each intersection leads to edge in the line-graph\n",
    "                    line_edges_weights_list.append(weight_function(nodes, edges_to_nodes_dict[neighbor],\n",
    "                                                                   edges_to_counts_dict[edge],\n",
    "                                                                   edges_to_counts_dict[neighbor]))\n",
    "\n",
    "        G = ig.Graph(n=len(items), edges=line_edges_list,\n",
    "                     edge_attrs={'weight': line_edges_weights_list},\n",
    "                     vertex_attrs={'label': list(line_nodes_ids_dict.keys())})\n",
    "        edges_list = G.get_edgelist()\n",
    "        print('saving line graph')\n",
    "        with open(LINEGRAPH_EDGES_PATH, 'w') as file:\n",
    "            lines = []\n",
    "            for edge_id in range(len(edges_list)):\n",
    "                edge_weight = G.es[edge_id][\"weight\"]\n",
    "                lines.append(f'{edges_list[edge_id][0]} {edges_list[edge_id][1]} {edge_weight}\\n')\n",
    "            file.writelines(lines)\n",
    "        with open(LINEGRAPH_NODES_PATH, 'w') as file:\n",
    "            file.writelines([str(G.vs[i]['label']) + '\\n' for i in range(len(items))])\n",
    "\n",
    "        print('line graph saved')\n",
    "        del G\n",
    "\n",
    "    with open(LINEGRAPH_EDGES_PATH, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    with open(LINEGRAPH_NODES_PATH, 'r') as file:\n",
    "        lines_nodes = file.readlines()\n",
    "    edges_list = []\n",
    "    weights = []\n",
    "    nodes = []\n",
    "    print('preparing data for line graph creation')\n",
    "    print(len(lines))\n",
    "    for line in lines:\n",
    "        from_node, to_node, weight = line.split(' ')\n",
    "        from_node = int(from_node)\n",
    "        to_node = int(to_node)\n",
    "        if from_node not in nodes:\n",
    "            nodes.append(from_node)\n",
    "        if to_node not in nodes:\n",
    "            nodes.append(to_node)\n",
    "        weight = float(weight)\n",
    "        edges_list.append((from_node, to_node))\n",
    "        weights.append(weight)\n",
    "\n",
    "    print('line graph creation')\n",
    "    G = ig.Graph(n=len(nodes), edges=edges_list,\n",
    "                 edge_attrs={'weight': weights},\n",
    "                 vertex_attrs={'label': [int(x) for x in lines_nodes]})\n",
    "    return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypergraph distance calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:16.230661Z",
     "start_time": "2024-10-24T08:06:16.228046Z"
    }
   },
   "outputs": [],
   "source": [
    "# suplementary function to calculate particulare path length\n",
    "def calc_path_weight(edges_to_counts_dict, line_graph, path):\n",
    "    line_ids_nodes_dict = {i: line_graph.vs[\"label\"][i] for i in range(len(line_graph.vs[\"label\"]))}\n",
    "    length = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        start = path[i]\n",
    "        end = path[i + 1]\n",
    "        e = line_graph.get_eid(start, end)\n",
    "        length += line_graph.es[e][\"weight\"]\n",
    "    length += (1 / 2) * (1 / edges_to_counts_dict[line_ids_nodes_dict[path[0]]] + \\\n",
    "                         1 / edges_to_counts_dict[line_ids_nodes_dict[path[-1]]])\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line-graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:19.451297Z",
     "start_time": "2024-10-24T08:06:16.231586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data for line graph creation\n",
      "539052\n",
      "line graph creation\n"
     ]
    }
   ],
   "source": [
    "# if we constructed line-graph once it is saved into suplementary/linegraphs to fasten further calculation\n",
    "line_graph = generate_weighted_line_graph(edges_to_nodes_dict, edges_to_counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(2205, 539052)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line_graph.vs), len(line_graph.es)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T08:06:19.455331Z",
     "start_time": "2024-10-24T08:06:19.452177Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "# функция для вычисления попарных расстояний\n",
    "# на вход принимает (line_graph, points, pos)\n",
    "# points - точки от которых надо посчитать расстояние до всех остальных\n",
    "# pos - номер воркера (для tqdm)\n",
    "# возвращает словарь dict[e1,e1]:distance\n",
    "def do_calc(data):\n",
    "    line_graph = data[0]\n",
    "    points = data[1]\n",
    "    pos = data[2]\n",
    "    all_paths_length = {}\n",
    "    sleep(max(pos, 0) / 10)\n",
    "    print('start', pos)\n",
    "    iter = tqdm(points, position=pos) if pos > 0 else points\n",
    "    for v1 in iter:\n",
    "        results_path = line_graph.get_shortest_paths(v1, output=\"epath\", weights=line_graph.es[\"weight\"])\n",
    "        for i, results in enumerate(results_path):\n",
    "            if len(results) > 0:\n",
    "                # Add up the weights across all edges on the shortest path\n",
    "                distance = 0\n",
    "                for e in results:\n",
    "                    distance += line_graph.es[e][\"weight\"]\n",
    "                all_paths_length[v1, i] = distance\n",
    "                all_paths_length[i, v1] = distance\n",
    "                # print(\"Shortest weighted distance is: \", distance)\n",
    "            else:\n",
    "                # print(f\"End node could not be reached! {v1} {v2}\")\n",
    "                pass\n",
    "    return all_paths_length\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T08:09:04.663044Z",
     "start_time": "2024-10-24T08:09:04.659895Z"
    }
   },
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Расчет всех расстояний"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   20.3s remaining:   30.4s\n",
      "[Parallel(n_jobs=5)]: Done   3 out of   5 | elapsed:   20.7s remaining:   13.8s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   21.3s finished\n"
     ]
    }
   ],
   "source": [
    "USE_JOB_LIB = True\n",
    "WORKERS = 5\n",
    "all_points = [i for i in range(len(line_graph.vs))]\n",
    "data = [(line_graph, all_points[i::WORKERS], i if not USE_JOB_LIB else -1) for i in range(WORKERS)]\n",
    "\n",
    "if WORKERS <= 1:\n",
    "    res = []\n",
    "    for d in data:\n",
    "        res.append(do_calc(d))\n",
    "elif USE_JOB_LIB:\n",
    "    res = Parallel(n_jobs=WORKERS, verbose=10)(delayed(do_calc)(d) for d in data)\n",
    "else:\n",
    "    with Pool(WORKERS) as p:\n",
    "        # res это список словарей вида {node_from: {node_to: length}}\n",
    "        res = p.map(do_calc, data)\n",
    "# мерж результатов воркеров\n",
    "all_paths_length = {}\n",
    "for r in res:\n",
    "    for (u, v), d in r.items():\n",
    "        all_paths_length[u, v] = d\n",
    "del res, data, all_points"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T08:09:30.833652Z",
     "start_time": "2024-10-24T08:09:06.650350Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":### Computation of distances between specified pairs of nodes"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/135 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e7b4f0341a840bc823bb7f02ac6cd47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# считаем self-loop (так как оно почему-то долго) и ребра\n",
    "self_loops_weight = {}\n",
    "all_edges = set()\n",
    "\n",
    "for edges in tqdm(nodes_to_edges_dict.values()):\n",
    "    for e in edges:\n",
    "        all_edges.add(e)\n",
    "        self_loops_weight[e] = line_graph.es[\"weight\"][line_graph.get_eid(e, e)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T08:10:04.127251Z",
     "start_time": "2024-10-24T08:09:30.834900Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/2205 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c11d1ba5190a48c29c3b13d38e577a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# матрица расстояний\n",
    "dst_mat = {}\n",
    "all_edges_list = list(all_edges)\n",
    "for i1 in trange(len(all_edges_list)):\n",
    "    for i2 in range(i1, len(all_edges_list)):\n",
    "        e1, e2 = all_edges_list[i1], all_edges_list[i2]\n",
    "        if (e1, e2) in dst_mat:\n",
    "            continue\n",
    "        if e1 == e2:\n",
    "            dst = self_loops_weight[e1]\n",
    "            dst += 1 / edges_to_counts_dict[e1]\n",
    "        else:\n",
    "            dst = all_paths_length[e1, e2]  # расстояние в line graph\n",
    "            dst += 1 / 2 / edges_to_counts_dict[e1] + 1 / 2 / edges_to_counts_dict[e2]\n",
    "        dst_mat[e1, e2] = dst\n",
    "        dst_mat[e2, e1] = dst\n",
    "del all_edges_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T08:10:09.434572Z",
     "start_time": "2024-10-24T08:10:04.128443Z"
    }
   },
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T08:10:24.383506Z",
     "start_time": "2024-10-24T08:10:09.435482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/135 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47ea86e54be14b9095f305274671046c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 14.944987773895264\n"
     ]
    }
   ],
   "source": [
    "dists_dict = {}\n",
    "paths_dict = {}\n",
    "node_names = list(nodes_to_edges_dict.keys())\n",
    "start_id = 0\n",
    "final_id = len(node_names) - 1\n",
    "# start_id = 120\n",
    "# final_id = 120\n",
    "\n",
    "file_path = pathlib.Path(f'{DIST_DIR}/dists_{data_type}_weighted-{start_id}-{final_id}.pickle')\n",
    "\n",
    "# if os.path.exists(file_path):\n",
    "#     pass\n",
    "# with open(file_path, 'rb') as handle:\n",
    "#     old_res, _ = pickle.load(handle)\n",
    "# else:\n",
    "if True:\n",
    "    time_start = time.time()\n",
    "    for id_from in trange(start_id, final_id + 1):\n",
    "        node_from = node_names[id_from]\n",
    "        dists = []\n",
    "        paths = []\n",
    "        for node in nodes_to_edges_dict.keys():\n",
    "            if node != node_from:\n",
    "                dst = float('inf')\n",
    "                for e1 in nodes_to_edges_dict[node_from]:\n",
    "                    for e2 in nodes_to_edges_dict[node]:\n",
    "                        dst = min(dst, dst_mat[e1, e2])\n",
    "                dists.append(dst)\n",
    "            else:\n",
    "                dists.append(0)\n",
    "            dists_dict[node_from] = dists\n",
    "\n",
    "    # we save calculated distances and corresponding shortest paths to fasten furter analysis\n",
    "    with open(file_path, 'wb') as handle:\n",
    "        pickle.dump((dists_dict, paths_dict), handle)\n",
    "    time_term = time.time()\n",
    "    print(f'Elapsed time {time_term - time_start}')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if data_type == '2000-2001':\n",
    "    with open(f'../data/dists_2000-2001_weighted-0-134.pickle', 'rb') as handle:\n",
    "        old_res, paths = pickle.load(handle)\n",
    "\n",
    "    for k in old_res:\n",
    "        for i in range(len(old_res[k])):\n",
    "            delta = old_res[k][i] - dists_dict[k][i]\n",
    "            if abs(delta) > 0.0001:\n",
    "                print(f'err {old_res[k][i]:.2f}_{dists_dict[k][i]:.2f}, {k} {list(nodes_to_edges_dict.keys())[i]}')\n",
    "    del old_res, paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-24T08:10:24.721791Z",
     "start_time": "2024-10-24T08:10:24.384102Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame containing calculated distances between every nodes pair\n",
    "hyper_dist_df = pd.DataFrame(dists_dict)\n",
    "hyper_dist_df.index = list(nodes_to_edges_dict.keys())\n",
    "hyper_dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted clique projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function generating weighted clique projection\n",
    "# weights = 1 / frequency of appearance\n",
    "def make_clique_projection_data(edges_to_nodes_dict, edges_to_counts_dict):\n",
    "    file_path = pathlib.Path(CLIQUE_PATH)\n",
    "\n",
    "    if not file_path.exists():\n",
    "        proj_edges_dict = {}\n",
    "        for edge, nodes in edges_to_nodes_dict.items():\n",
    "            for i in range(len(nodes) - 1):\n",
    "                for j in range(i + 1, len(nodes)):\n",
    "                    node_from = nodes[i]\n",
    "                    node_to = nodes[j]\n",
    "                    if not (((node_from, node_to) in proj_edges_dict.keys())\n",
    "                            or ((node_to, node_from) in proj_edges_dict.keys())):\n",
    "                        proj_edges_dict[(node_from, node_to)] = edges_to_counts_dict[edge]\n",
    "                    else:\n",
    "                        if ((node_from, node_to) in proj_edges_dict.keys()):\n",
    "                            proj_edges_dict[(node_from, node_to)] += edges_to_counts_dict[edge]\n",
    "                        else:\n",
    "                            proj_edges_dict[(node_to, node_from)] += edges_to_counts_dict[edge]\n",
    "\n",
    "        with open(CLIQUE_PATH, 'w') as handle:\n",
    "            for (node_from, node_to), weight in proj_edges_dict.items():\n",
    "                handle.write(f'{node_from} {node_to} {weight}')\n",
    "                handle.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create cluque projection if it wasn't created previously\n",
    "make_clique_projection_data(edges_to_nodes_dict, edges_to_counts_dict)\n",
    "\n",
    "# load and clique projection\n",
    "proj_graph_file = CLIQUE_PATH\n",
    "with open(proj_graph_file) as file:\n",
    "    lines = file.readlines()\n",
    "    edges_list = []\n",
    "    weights_list = []\n",
    "    nodes_dict = {}\n",
    "    i = -1\n",
    "    for line in lines:\n",
    "        from_node, to_node, weight = line.split(\" \")\n",
    "\n",
    "        # from_node = int(from_node)\n",
    "        # to_node = int(to_node)\n",
    "\n",
    "        if not from_node in nodes_dict.keys():\n",
    "            i += 1\n",
    "            from_id = i\n",
    "            nodes_dict[from_node] = i\n",
    "        else:\n",
    "            from_id = nodes_dict[from_node]\n",
    "        if not to_node in nodes_dict.keys():\n",
    "            i += 1\n",
    "            to_id = i\n",
    "            nodes_dict[to_node] = i\n",
    "        else:\n",
    "            to_id = nodes_dict[to_node]\n",
    "        edges_list.append([from_id, to_id])\n",
    "        weights_list.append(1 / float(weight))\n",
    "\n",
    "proj_graph = ig.Graph(edges_list)\n",
    "proj_graph.es[\"weight\"] = weights_list\n",
    "\n",
    "proj_dist_dict = {}\n",
    "proj_dist_path = {}\n",
    "\n",
    "# calculation of distances and paths in cluque projection\n",
    "\n",
    "for from_node in dists_dict.keys():\n",
    "    from_node_id = nodes_dict[from_node]\n",
    "    dists = []\n",
    "    paths_tmp = []\n",
    "    for node in list(nodes_to_edges_dict.keys()):\n",
    "        node_id = nodes_dict[node]\n",
    "        paths = proj_graph.get_shortest_paths(from_node_id, node_id, weights=proj_graph.es[\"weight\"], output=\"epath\")\n",
    "        paths_tmp.append(paths[0])\n",
    "        distance = 0\n",
    "        for e in paths[0]:\n",
    "            distance += proj_graph.es[e][\"weight\"]\n",
    "        dists.append(distance)\n",
    "\n",
    "    proj_dist_dict[from_node] = dists\n",
    "    proj_dist_path[from_node] = paths_tmp\n",
    "\n",
    "# data frame containing dists in clique proj for every nodes pair\n",
    "proj_dist_df = pd.DataFrame(proj_dist_dict)\n",
    "proj_dist_df.index = list(nodes_to_edges_dict.keys())\n",
    "proj_dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_dist_df.to_csv(f\"results_hypergraph_dist_{data_type}.csv\")\n",
    "proj_dist_df.to_csv(f\"results_clique-proj_dist_{data_type}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hg_dists = []\n",
    "all_proj_dists = []\n",
    "\n",
    "for i in range(len(node_names) - 1):\n",
    "    for j in range(i + 1, len(node_names)):\n",
    "        from_node = node_names[i]\n",
    "        to_node = node_names[j]\n",
    "        if not from_node == to_node:\n",
    "            all_hg_dists.append(dists_dict[from_node][j])\n",
    "            all_proj_dists.append(proj_dist_dict[from_node][j])\n",
    "max_q = 10\n",
    "hg_quantiles = [np.quantile(all_hg_dists, q / max_q) for q in range(1, max_q)]\n",
    "proj_quantiles = [np.quantile(all_proj_dists, q / max_q) for q in range(1, max_q)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_dict = {\n",
    "    \"from node id\": [],\n",
    "    \"to node id\": [],\n",
    "    \"from node\": [],\n",
    "    \"to node\": [],\n",
    "    \"hypergraph distance\": [],\n",
    "    \"projected distance\": [],\n",
    "    \"diff\": [],\n",
    "    \"hypergraph rank\": [],\n",
    "    \"projected rank\": [],\n",
    "    \"rank difference\": []\n",
    "}\n",
    "for i in range(len(node_names) - 1):\n",
    "    for j in range(i + 1, len(node_names)):\n",
    "        from_node = node_names[i]\n",
    "        to_node = node_names[j]\n",
    "        hg_dist = dists_dict[from_node][j]\n",
    "        proj_dist = proj_dist_dict[from_node][j]\n",
    "\n",
    "        if hg_dist <= hg_quantiles[0]:\n",
    "            compare_dict[\"hypergraph rank\"].append(1)\n",
    "        elif hg_dist > hg_quantiles[-1]:\n",
    "            compare_dict[\"hypergraph rank\"].append(max_q)\n",
    "        else:\n",
    "            for q in range(1, max_q - 1):\n",
    "                if hg_dist > hg_quantiles[q - 1] and hg_dist <= hg_quantiles[q]:\n",
    "                    compare_dict[\"hypergraph rank\"].append(q + 1)\n",
    "\n",
    "        if proj_dist <= proj_quantiles[0]:\n",
    "            compare_dict[\"projected rank\"].append(1)\n",
    "        elif proj_dist > proj_quantiles[-1]:\n",
    "            compare_dict[\"projected rank\"].append(max_q)\n",
    "        else:\n",
    "            for q in range(1, max_q - 1):\n",
    "                if proj_dist > proj_quantiles[q - 1] and proj_dist <= proj_quantiles[q]:\n",
    "                    compare_dict[\"projected rank\"].append(q + 1)\n",
    "\n",
    "        compare_dict[\"from node id\"].append(i)\n",
    "        compare_dict[\"to node id\"].append(j)\n",
    "        compare_dict[\"from node\"].append(from_node)\n",
    "        compare_dict[\"to node\"].append(to_node)\n",
    "        compare_dict[\"hypergraph distance\"].append(hg_dist)\n",
    "        compare_dict[\"projected distance\"].append(proj_dist)\n",
    "        compare_dict[\"diff\"].append(hg_dist - proj_dist)\n",
    "        compare_dict[\"rank difference\"].append(\n",
    "            abs(compare_dict[\"projected rank\"][-1] - compare_dict[\"hypergraph rank\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame(compare_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.sort_values(by=[\"rank difference\"], ascending=False, inplace=True)\n",
    "compare_df.to_csv(f\"compare_{data_type}.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_matrix = np.zeros(shape=(max_q, max_q))\n",
    "\n",
    "N_pairs = len(compare_dict[\"hypergraph rank\"])\n",
    "\n",
    "for i in range(N_pairs):\n",
    "    h_rank = compare_dict[\"hypergraph rank\"][i]\n",
    "    g_rank = compare_dict[\"projected rank\"][i]\n",
    "    quant_matrix[h_rank - 1, g_rank - 1] += 1 / N_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(quant_matrix, cmap=\"binary\", )\n",
    "plt.xticks(range(0, max_q), labels=range(1, max_q + 1))\n",
    "plt.yticks(range(0, max_q), labels=range(1, max_q + 1))\n",
    "plt.xlabel('hypergraph distance rank')\n",
    "plt.ylabel('projected distance rank')\n",
    "plt.colorbar()\n",
    "plt.title(data_type[:4])\n",
    "plt.savefig(f'../figures/ranks_dist_{data_type}.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_name = \"q-fin.st\"\n",
    "to_name = \"q-fin.rm\"\n",
    "from_id = 65\n",
    "to_id = 67\n",
    "dists_dict[from_name][to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dist_dict[from_name][to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_dict[from_name][to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for edge in paths_dict[from_name][to_id][0]:\n",
    "    string = ''\n",
    "    for x in edges_to_nodes_dict[edge]:\n",
    "        string += x + ' '\n",
    "    print(f'{string} weight = {edges_to_counts_dict[edge]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dist_path[from_name][to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in proj_dist_path[from_name][to_id]:\n",
    "    print(f'weight = {1 / proj_graph.es[edge][\"weight\"]}')\n",
    "    print(node_names[proj_graph.es[edge].source])\n",
    "    print(node_names[proj_graph.es[edge].target])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
